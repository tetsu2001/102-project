{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "131eaa77-ab5b-46a8-8be5-4401810fa774",
   "metadata": {},
   "source": [
    "## December 10th GLM From beginning to end with descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7984a-0b2c-410c-901b-02a2de8b8ca5",
   "metadata": {},
   "source": [
    "# Import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465d2f39-a473-40da-b44c-f18c83523c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm\n",
    "from fuzzywuzzy import fuzz\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, balanced_accuracy_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, balanced_accuracy_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d23cb-a295-4ec5-be60-55b32b42d624",
   "metadata": {},
   "source": [
    "# Functions I wrote to do this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c92b317-2906-4dd5-bf6a-24dff03b3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_cols(df, nan_threshold=20):\n",
    "    few_NaNs_cols = []\n",
    "    for col in df.columns:\n",
    "        if (df[col].nunique(dropna=False) == 2) or (df[col].nunique(dropna=True) == 2):\n",
    "            unique_vals = df[col].unique()\n",
    "            if (unique_vals[0] !=0 and unique_vals[1] !=0):\n",
    "                print(f\"col:{col}\\n0 means:{unique_vals[0]}\\n1 means: {unique_vals[1]}\\n\")\n",
    "                df[col] = df[col].replace({unique_vals[0]: int(0), unique_vals[1]: int(1)})\n",
    "            df[col].fillna(0, inplace=True) #now this will only make sense tho if we OHE first.    \n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_columns(df, col_lst):\n",
    "    for i in col_lst:\n",
    "        if i in df.columns:\n",
    "            df.drop(i, axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def lowercase_column(df, column_name):\n",
    "    if column_name in df.columns:\n",
    "        df[column_name] = df[column_name].astype(str).str.lower()\n",
    "    return df\n",
    "\n",
    "def count_candidates_by_district(df, district_column, new_column_name):\n",
    "    district_counts = df.groupby(district_column).size().reset_index(name=new_column_name)\n",
    "    df_merged = df.merge(district_counts, on=district_column)\n",
    "    df_merged = df_merged[df_merged[new_column_name]>1]\n",
    "    return df_merged\n",
    "\n",
    "def move_column_to_front(df, col_lst):\n",
    "    for column_name in col_lst:\n",
    "        if column_name in df.columns:\n",
    "            df = df[[column_name] + [col for col in df.columns if col != column_name]]\n",
    "    return df\n",
    "\n",
    "def get_info(df):\n",
    "    print(f\"COL VALUE TYPES \\n{df.dtypes} \\n\\ndf shape:{df.shape}\\n\\nall the columns:\\n{df.columns}\")\n",
    "    \n",
    "    \n",
    "def rename_column_if_exists(df, old_name, new_name):\n",
    "    if old_name in df.columns:\n",
    "        df.rename(columns={old_name: new_name}, inplace=True)\n",
    "    return df\n",
    "    \n",
    "def replace_values_fill_na(df, column_name, replace_dict):\n",
    "    if column_name in df.columns:\n",
    "        df[column_name] = df[column_name].replace(replace_dict).fillna(0)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def get_ohe_cols(df, unique_limit=16, exclude = ['total_runners_house','total_runners']):\n",
    "    #object_cols = df.select_dtypes(include=['object']).columns\n",
    "    res = [col for col in df.columns if ((df[col].nunique(dropna=False) <= unique_limit) and (df[col].nunique(dropna=False)>2) and (col != 'total_runners') and (col != 'General Status') and (col !='Total Endorsements'))]\n",
    "    return res\n",
    "\n",
    "\n",
    "def convert_type(df, col_lst):\n",
    "    for column_name in col_lst:\n",
    "        if column_name in df.columns and df[column_name].dtype != 'int64':\n",
    "            df[column_name] = df[column_name].astype(int)\n",
    "\n",
    "            \n",
    "def get_X_df(df, y_col):\n",
    "    return df.drop(y_col, axis=1)\n",
    "\n",
    "# def zero_dropper(df):\n",
    "#     for col in df.columns:\n",
    "#         if ((df[col]==0).mean() >= 0.90):\n",
    "#             df = df.drop(col, axis=1)\n",
    "#     return df\n",
    "\n",
    "def drop_VIF_col(X, threshold=2):\n",
    "    while True:\n",
    "        vif_info = pd.DataFrame()\n",
    "        vif_info['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "        vif_info['Column'] = X.columns\n",
    "        vif_info = vif_info.sort_values('VIF', ascending=False)\n",
    "        max_VIF = vif_info['VIF'].iloc[0]\n",
    "\n",
    "        if max_VIF > threshold:\n",
    "            to_drop = vif_info['Column'].iloc[0]\n",
    "            print(f\"Dropped: {to_drop} with VIF of {max_VIF}\")\n",
    "            X = X.drop(to_drop, axis=1)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return X  # Returning the modified DataFrame\n",
    "\n",
    "def change_to_int(df, column):\n",
    "    df[column] = df[column].astype(int)\n",
    "    \n",
    "    \n",
    "def convert_to_int_if_possible(df, col_lst):\n",
    "    for column_name in col_lst:\n",
    "        temp_col = pd.to_numeric(df[column_name], errors='coerce')\n",
    "        if temp_col.isna().sum() == 0:\n",
    "            if all(temp_col.dropna() == temp_col.dropna().astype(int)):\n",
    "                df[column_name] = temp_col.astype(int)\n",
    "    return df\n",
    "\n",
    "def aic(X, y):\n",
    "    best_features = []\n",
    "    best_aic = float('inf')\n",
    "\n",
    "    for feature in X.columns:\n",
    "        # Create a temporary DataFrame with the current set of best features plus the new feature\n",
    "        X_temp = sm.add_constant(X[best_features + [feature]])\n",
    "\n",
    "       \n",
    "        model = sm.Logit(y, X_temp)  # Fit the logistic regression model\n",
    "        result = model.fit()  # disp=0 suppresses the fit output\n",
    "\n",
    "        # Check AIC and update if it is lower\n",
    "        if result.aic < best_aic:\n",
    "            best_aic = result.aic\n",
    "            best_features.append(feature)\n",
    "\n",
    "    # Fit the final model with the best features\n",
    "    X_final = sm.add_constant(X[best_features])\n",
    "    final_model = sm.Logit(y, X_final)\n",
    "    final_result = final_model.fit()\n",
    "\n",
    "    # You might want to return the final model, its summary, or AIC\n",
    "    print(f\"{best_features}\")\n",
    "    return final_result.summary(), final_result.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb11b6c5-e4d4-4fa9-9853-dced6f4d87de",
   "metadata": {},
   "source": [
    "Importing the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de4bbbe-b445-4bf5-b924-1c022c4747aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEC_merged = pd.read_csv('final_fec_merged.csv')\n",
    "FEC_merged = convert_to_int_if_possible(FEC_merged,list(FEC_merged.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ca882-9cb3-4897-a8bb-d00806ce39cf",
   "metadata": {},
   "source": [
    "## I'm going to OHE the columns that have more than two unique values (including NaNs) for example Emily Endorsed Yes, Emily Endorsed No, and Emily Endorsed NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3caa45-0566-4999-b6fb-a409892a880f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9ddb1fc-a42b-41f0-bd4f-5a87beae2b6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78f9fd-dfc9-429d-a869-2d6c2e69359d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
