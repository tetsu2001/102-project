{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f8cf02-0787-4558-979c-52d19d685a64",
   "metadata": {},
   "source": [
    "Importing libraries and cleaning up the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "981692f2-6745-4060-909e-f710496f2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "dem_candidates = pd.read_csv('../datasets/dem_candidates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83adc9cb-e3d9-4bd3-bf28-b0c29c49cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dem_candidates = pd.read_csv('ready for model building.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "057bfcde-20d4-491a-bdef-bf9e57636d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General Status</th>\n",
       "      <th>Female</th>\n",
       "      <th>total_runners</th>\n",
       "      <th>Partisan Lean</th>\n",
       "      <th>Primary %</th>\n",
       "      <th>Race</th>\n",
       "      <th>Veteran?</th>\n",
       "      <th>LGBTQ?</th>\n",
       "      <th>Elected Official?</th>\n",
       "      <th>Self-Funder?</th>\n",
       "      <th>...</th>\n",
       "      <th>PCCC Endorsed?_Yes</th>\n",
       "      <th>PCCC Endorsed?_nan</th>\n",
       "      <th>Indivisible Endorsed?_Yes</th>\n",
       "      <th>Indivisible Endorsed?_nan</th>\n",
       "      <th>WFP Endorsed?_Yes</th>\n",
       "      <th>WFP Endorsed?_nan</th>\n",
       "      <th>VoteVets Endorsed?_Yes</th>\n",
       "      <th>VoteVets Endorsed?_nan</th>\n",
       "      <th>No Labels Support?_Yes</th>\n",
       "      <th>No Labels Support?_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-30.680000</td>\n",
       "      <td>19.230000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-30.680000</td>\n",
       "      <td>80.769997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-33.080002</td>\n",
       "      <td>39.560001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-33.080002</td>\n",
       "      <td>60.439999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-33.660000</td>\n",
       "      <td>34.240002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-35.330002</td>\n",
       "      <td>62.570000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-47.480000</td>\n",
       "      <td>24.639999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-47.480000</td>\n",
       "      <td>7.240000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-47.480000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-47.480000</td>\n",
       "      <td>52.160000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     General Status  Female  total_runners  Partisan Lean  Primary %  Race  \\\n",
       "0                 0       1              2     -30.680000  19.230000     1   \n",
       "1                 1       0              2     -30.680000  80.769997     1   \n",
       "2                 0       1              2     -33.080002  39.560001     1   \n",
       "3                 1       1              2     -33.080002  60.439999     0   \n",
       "4                 0       1              2     -33.660000  34.240002     1   \n",
       "..              ...     ...            ...            ...        ...   ...   \n",
       "573               1       1              2     -35.330002  62.570000     0   \n",
       "574               0       0              4     -47.480000  24.639999     0   \n",
       "575               0       1              4     -47.480000   7.240000     0   \n",
       "576               0       0              4     -47.480000  15.960000     0   \n",
       "577               1       0              4     -47.480000  52.160000     1   \n",
       "\n",
       "     Veteran?  LGBTQ?  Elected Official?  Self-Funder?  ...  \\\n",
       "0           0       0                  0             0  ...   \n",
       "1           1       0                  0             0  ...   \n",
       "2           1       0                  0             0  ...   \n",
       "3           0       0                  0             0  ...   \n",
       "4           0       0                  0             0  ...   \n",
       "..        ...     ...                ...           ...  ...   \n",
       "573         0       0                  0             0  ...   \n",
       "574         0       0                  0             0  ...   \n",
       "575         0       0                  0             0  ...   \n",
       "576         0       0                  0             0  ...   \n",
       "577         1       0                  1             0  ...   \n",
       "\n",
       "     PCCC Endorsed?_Yes  PCCC Endorsed?_nan  Indivisible Endorsed?_Yes  \\\n",
       "0                     0                   1                          0   \n",
       "1                     0                   1                          0   \n",
       "2                     0                   1                          0   \n",
       "3                     0                   1                          0   \n",
       "4                     0                   1                          0   \n",
       "..                  ...                 ...                        ...   \n",
       "573                   0                   1                          0   \n",
       "574                   0                   1                          0   \n",
       "575                   0                   1                          0   \n",
       "576                   0                   1                          0   \n",
       "577                   0                   1                          0   \n",
       "\n",
       "     Indivisible Endorsed?_nan  WFP Endorsed?_Yes  WFP Endorsed?_nan  \\\n",
       "0                            1                  0                  1   \n",
       "1                            1                  0                  1   \n",
       "2                            1                  0                  1   \n",
       "3                            1                  0                  1   \n",
       "4                            1                  0                  1   \n",
       "..                         ...                ...                ...   \n",
       "573                          1                  0                  1   \n",
       "574                          1                  0                  0   \n",
       "575                          1                  0                  0   \n",
       "576                          1                  0                  0   \n",
       "577                          1                  1                  0   \n",
       "\n",
       "     VoteVets Endorsed?_Yes  VoteVets Endorsed?_nan  No Labels Support?_Yes  \\\n",
       "0                         0                       1                       0   \n",
       "1                         0                       1                       0   \n",
       "2                         0                       1                       0   \n",
       "3                         0                       1                       0   \n",
       "4                         0                       1                       0   \n",
       "..                      ...                     ...                     ...   \n",
       "573                       0                       0                       0   \n",
       "574                       0                       0                       0   \n",
       "575                       0                       0                       0   \n",
       "576                       0                       0                       0   \n",
       "577                       1                       0                       0   \n",
       "\n",
       "     No Labels Support?_nan  \n",
       "0                         1  \n",
       "1                         1  \n",
       "2                         1  \n",
       "3                         1  \n",
       "4                         1  \n",
       "..                      ...  \n",
       "573                       1  \n",
       "574                       1  \n",
       "575                       1  \n",
       "576                       1  \n",
       "577                       1  \n",
       "\n",
       "[578 rows x 131 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_dem_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06c137af-01e2-4b10-b9fc-9d2a0b241c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = updated_dem_candidates.drop('General Status', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e03c68fe-0e2c-4c17-8a7b-63450cf86ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = predictors.drop('Primary %', axis=1)\n",
    "predictors = predictors.drop('Female', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54ecc183-59f6-40f6-93b2-de53730350f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(578, 128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "693a7b58-e4db-4537-a660-60cd2a8b329a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(578, 131)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_dem_candidates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3eecfde7-eeb9-49cb-a237-55d7615867a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = predictors.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78dcb35c-dcf2-4e9f-a28f-26567ec953ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538835\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538658\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538612\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538523\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538538\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.530815\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.528535\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.526154\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.523174\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.491557\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.460196\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.460163\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.455556\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.455388\n",
      "         Iterations 34\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Fit the logistic regression model\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mLogit(y, X)\n\u001b[0;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Check AIC and update if it is lower\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39maic \u001b[38;5;241m<\u001b[39m best_aic:\n",
      "File \u001b[0;32m/srv/conda/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py:1983\u001b[0m, in \u001b[0;36mLogit.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1980\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(DiscreteModel\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m,\n\u001b[1;32m   1982\u001b[0m         full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1983\u001b[0m     bnryfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1984\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1985\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1986\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1989\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1991\u001b[0m     discretefit \u001b[38;5;241m=\u001b[39m LogitResults(\u001b[38;5;28mself\u001b[39m, bnryfit)\n\u001b[1;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[0;32m/srv/conda/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py:230\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "File \u001b[0;32m/srv/conda/lib/python3.9/site-packages/statsmodels/base/model.py:579\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m cov_params_func(\u001b[38;5;28mself\u001b[39m, xopt, retvals)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m full_output:\n\u001b[0;32m--> 579\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mretvals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHessian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hessian:\n\u001b[1;32m    581\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhessian(xopt)\n",
      "File \u001b[0;32m/srv/conda/lib/python3.9/site-packages/numpy/linalg/linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/srv/conda/lib/python3.9/site-packages/numpy/linalg/linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "X = predictors.fillna(0)\n",
    "y = updated_dem_candidates['General Status']\n",
    "\n",
    "best_features = []\n",
    "best_aic = float('inf') \n",
    "\n",
    "for feature in predictors.columns:\n",
    "    # Add a constant term and the current feature\n",
    "    X = sm.add_constant(predictors[best_features + [feature]])\n",
    "\n",
    "    # Fit the logistic regression model\n",
    "    model = sm.Logit(y, X)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Check AIC and update if it is lower\n",
    "    if result.aic < best_aic:\n",
    "        best_aic = result.aic\n",
    "        best_features.append(feature)\n",
    "\n",
    "# Fit the final model with the best features\n",
    "X_final = sm.add_constant(predictors[best_features])\n",
    "final_model = sm.Logit(y, X_final)\n",
    "final_result = final_model.fit()\n",
    "\n",
    "\n",
    "print(final_result.summary(), final_result.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349af56-a806-4b0b-947c-124f8b6edda7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sara -- Frequentist Model using statsmodels.api\n",
    "Why: From lab 5:\n",
    "Let's start by considering the problem from a frequentist lens. To do this, we'll use the statsmodels.api, which allows us to create a model in just a few lines of code.\n",
    "\n",
    "After fitting our model, we can call the .summary() method, and get a breakdown of our model and some details on how well it fit our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c776f91d-49a3-4888-bf2f-b0c723282c43",
   "metadata": {},
   "source": [
    "2a) Fit Poisson GLM model where Temp_Anomaly is a covariate (exogenous variable): No need to modify\n",
    "freq_model = sm.GLM(df[\"Num_Storms\"], exog = sm.add_constant(df[\"Temp_Anomaly\"]), \n",
    "                  family=sm.families.Poisson())\n",
    "freq_res = freq_model.fit()\n",
    "print(freq_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7a5a7d2a-2c0e-46d3-830e-2ee3b65a89b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:         General Status   No. Observations:                  633\n",
      "Model:                            GLM   Df Residuals:                      623\n",
      "Model Family:                Binomial   Df Model:                            9\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -335.48\n",
      "Date:                Wed, 06 Dec 2023   Deviance:                       670.95\n",
      "Time:                        23:49:03   Pearson chi2:                     622.\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.09850\n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 0.2869      0.334      0.859      0.390      -0.368       0.941\n",
      "Partisan Lean        -0.0070      0.006     -1.241      0.215      -0.018       0.004\n",
      "Race                  0.0243      0.235      0.103      0.918      -0.437       0.486\n",
      "Veteran?             -0.0363      0.260     -0.140      0.889      -0.545       0.473\n",
      "LGBTQ?                0.2103      0.442      0.476      0.634      -0.656       1.077\n",
      "Self-Funder?          0.7353      0.490      1.502      0.133      -0.224       1.695\n",
      "STEM?                -0.5217      0.269     -1.938      0.053      -1.049       0.006\n",
      "Obama Alum?           0.9608      0.440      2.182      0.029       0.098       1.824\n",
      "Elected Official?     1.0651      0.306      3.484      0.000       0.466       1.664\n",
      "total_runners        -0.3619      0.064     -5.645      0.000      -0.488      -0.236\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "predictors = [ 'Partisan Lean', 'Race', 'Veteran?', 'LGBTQ?', 'Self-Funder?', 'STEM?','Obama Alum?', 'Elected Official?','total_runners']\n",
    "# Fit Poisson GLM model where Temp_Anomaly is a covariate (exogenous variable): No need to modify\n",
    "freq_model = sm.GLM(endog = house[\"General Status\"], exog = sm.add_constant(house[predictors]), \n",
    "                  family=sm.families.Binomial())\n",
    "freq_res = freq_model.fit()\n",
    "print(freq_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd584534-b91b-47a3-8fb6-e50dad00e082",
   "metadata": {},
   "source": [
    "using predictors that have no relationship with the response tends to cause a deterioration in the test error rate (since such predictors cause an increase in variance without a corresponding decrease in bias), and so removing such predictors may in turn yield an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b38fc-1fb0-4bf5-b027-d68953207db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f56adcc6-8a01-4cdc-8dc2-5bbde6c4f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = (Smarket.Year < 2005)\n",
    "# Smarket_train = Smarket.loc[train]\n",
    "# Smarket_test = Smarket.loc[∼train]\n",
    "\n",
    "# X_train, X_test = X.loc[train], X.loc[∼train]\n",
    "# y_train, y_test = y.loc[train], y.loc[∼train]\n",
    "# glm_train = sm.GLM(\n",
    "#     y_train,\n",
    "#     X_train,\n",
    "#     family=sm.families.Binomial()\n",
    "# )\n",
    "# results = glm_train.fit()\n",
    "# probs = results.predict(exog=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459299ee-8b4a-4c9b-96f8-10216c9bab53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fitting a Frequentist Logistic Regression model using Sklearn:\n",
    "To choose the predictors (X) we used domain knowledge. \n",
    "- X: Predictors of General Status\n",
    "- Y: General Status (1 if the candidate advanced to the general election, 0 if not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "81a02c96-bb75-4104-a971-45b959741c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#setting up the logistic regression model by splitting into train and test\n",
    "train, test = train_test_split(house, test_size = .30, random_state = 101)\n",
    "predictors = [ 'Partisan Lean', 'Race', 'Veteran?', 'LGBTQ?', 'Self-Funder?', 'STEM?','Obama Alum?', 'total_runners']\n",
    "X_train, y_train = train[predictors], train['General Status']\n",
    "X_test, y_test = test[predictors], test['General Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1fb8f43c-3f9a-4a8e-a60e-ac86ea0d30f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7631578947368421\n"
     ]
    }
   ],
   "source": [
    "# X_train = train[['Partisan Lean', 'Race',\n",
    "#        'Veteran?', 'LGBTQ?', 'Elected Official?', 'Self-Funder?', 'STEM?',\n",
    "#        'Obama Alum?', 'Party Support?', 'Emily Endorsed?', 'total_runners']]\n",
    "# y_train = train['General Status']\n",
    "\n",
    "# X_test = test[['Partisan Lean', 'Race',\n",
    "#        'Veteran?', 'LGBTQ?', 'Elected Official?', 'Self-Funder?', 'STEM?',\n",
    "#        'Obama Alum?', 'Party Support?', 'Emily Endorsed?', 'total_runners']]\n",
    "# y_test = test['General Status']\n",
    "\n",
    "logisticmodel = LogisticRegression(penalty='none', solver='lbfgs')\n",
    "\n",
    "logisticmodel.fit(X_test, y_test)\n",
    "\n",
    "probs = logisticmodel.predict_proba(X_test)[:, 1]\n",
    "y_hat = (probs > 0.5).astype(int)\n",
    "\n",
    "accuracy = np.mean(y_test == y_hat)\n",
    "print(f\"Accuracy on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62813175-e530-4638-a44c-8e4413f9e18f",
   "metadata": {},
   "source": [
    "We first created a Logistic Regression model using a subset of features in the house dataset. We employed feature engineering to include a column of how many total runners were participating in the election. Because the data on each candidate is not independent since the outcome of a race for a single candidate is affected by the outcome for another candidate in that same race, we included the number of total runners. Additionally, because both Biden and Warren only endorsed 5 candidates each, we excluded those features. Emily's list endorsed 42 candidates in the 2018 house of representative elections, so we intentionally included this column. There were 33 Obama Alums, so we included this as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2de59a76-7afd-4618-9d06-062cf7457295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house['Obama Alum?'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd19493-1750-4e03-9088-ff67aa5d879d",
   "metadata": {},
   "source": [
    "## Fitting a Logistic Regression model using statsmodel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a9d1c8bc-e397-4bee-81b6-3d066c5da0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.529978\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         General Status   No. Observations:                  633\n",
      "Model:                          Logit   Df Residuals:                      623\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Wed, 06 Dec 2023   Pseudo R-squ.:                 0.08911\n",
      "Time:                        23:49:03   Log-Likelihood:                -335.48\n",
      "converged:                       True   LL-Null:                       -368.29\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.084e-10\n",
      "=====================================================================================\n",
      "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 0.2869      0.334      0.859      0.390      -0.368       0.941\n",
      "Partisan Lean        -0.0070      0.006     -1.241      0.215      -0.018       0.004\n",
      "Race                  0.0243      0.235      0.103      0.918      -0.437       0.486\n",
      "Veteran?             -0.0363      0.260     -0.140      0.889      -0.545       0.473\n",
      "LGBTQ?                0.2103      0.442      0.476      0.634      -0.656       1.077\n",
      "Self-Funder?          0.7353      0.490      1.502      0.133      -0.224       1.695\n",
      "STEM?                -0.5217      0.269     -1.938      0.053      -1.049       0.006\n",
      "Obama Alum?           0.9608      0.440      2.182      0.029       0.098       1.824\n",
      "Elected Official?     1.0651      0.306      3.484      0.000       0.466       1.664\n",
      "total_runners        -0.3619      0.064     -5.645      0.000      -0.488      -0.236\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "predictors = [ 'Partisan Lean', 'Race', 'Veteran?', 'LGBTQ?', 'Self-Funder?', 'STEM?','Obama Alum?', 'Elected Official?','total_runners']\n",
    "X = house[predictors]  # independent variables\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = house['General Status']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f710cdb3-918c-4501-b777-1a6178209131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690.9515452801878 735.4562495016296\n"
     ]
    }
   ],
   "source": [
    "print(result.aic, result.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab702174-35d5-4e99-bfbe-d88506136893",
   "metadata": {},
   "source": [
    "While our initial model had a decent accuracy of approximately 84%, we can further optimize our model by selecting the best combination of features. As we can see in the summary from the model above, the log-likelihood is pretty low. Additionally, when we interpret the confidence intervals for the probabilities of the coefficients, we can see that many of these intervals include 0. Thus, it would make sense to re-evaluate these features or take them out. Additionally, when comparing the coefficients, we can see that some of the coefficients only have a marginal affect on the dependent variable, such as 'LGBTQ?' or 'Self-Funder?'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d87af89-9071-490e-a107-f862dcb19561",
   "metadata": {},
   "source": [
    "Forward selection of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1ccbba2f-b2c5-4055-90eb-a4ada5372426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574478\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574083\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574473\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574478\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574388\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.570005\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.566736\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.558117\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.531759\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.531759\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         General Status   No. Observations:                  633\n",
      "Model:                          Logit   Df Residuals:                      627\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Wed, 06 Dec 2023   Pseudo R-squ.:                 0.08605\n",
      "Time:                        23:49:04   Log-Likelihood:                -336.60\n",
      "converged:                       True   LL-Null:                       -368.29\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.426e-12\n",
      "=====================================================================================\n",
      "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 0.2938      0.319      0.922      0.356      -0.331       0.918\n",
      "Partisan Lean        -0.0060      0.005     -1.100      0.271      -0.017       0.005\n",
      "STEM?                -0.4862      0.267     -1.819      0.069      -1.010       0.038\n",
      "Obama Alum?           0.9746      0.434      2.244      0.025       0.123       1.826\n",
      "Elected Official?     1.0181      0.302      3.374      0.001       0.427       1.610\n",
      "total_runners        -0.3501      0.063     -5.553      0.000      -0.474      -0.227\n",
      "===================================================================================== 685.2066955439864\n"
     ]
    }
   ],
   "source": [
    "predictors = [ 'Partisan Lean', 'Race', 'Veteran?', 'LGBTQ?', 'Self-Funder?', 'STEM?','Obama Alum?', 'Elected Official?','total_runners']\n",
    "all_predictors_df = house[predictors]\n",
    "\n",
    "\n",
    "y = house['General Status']\n",
    "\n",
    "best_features = []\n",
    "best_aic = float('inf') \n",
    "\n",
    "for feature in all_predictors_df.columns:\n",
    "    # Add a constant term and the current feature\n",
    "    X = sm.add_constant(all_predictors_df[best_features + [feature]])\n",
    "\n",
    "    # Fit the logistic regression model\n",
    "    model = sm.Logit(y, X)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Check AIC and update if it is lower\n",
    "    if result.aic < best_aic:\n",
    "        best_aic = result.aic\n",
    "        best_features.append(feature)\n",
    "\n",
    "# Fit the final model with the best features\n",
    "X_final = sm.add_constant(all_predictors_df[best_features])\n",
    "final_model = sm.Logit(y, X_final)\n",
    "final_result = final_model.fit()\n",
    "\n",
    "\n",
    "print(final_result.summary(), final_result.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d88b3f-cf09-4cd7-b123-f5fc59aa40ea",
   "metadata": {},
   "source": [
    "@ Nikki I am not sure what this is for? \n",
    "train, test = train_test_split(all_predictors_df, test_size = .30, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3e62f-da59-4870-920f-c2e8b5a9719f",
   "metadata": {},
   "source": [
    "Backward selection of features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "da208092-485e-4280-a2c5-d3f709d6344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.529978\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539299\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.531212\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532558\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535826\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535916\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532589\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.571044\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532723\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532730\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535342\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532730\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         General Status   No. Observations:                  633\n",
      "Model:                          Logit   Df Residuals:                      628\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Wed, 06 Dec 2023   Pseudo R-squ.:                 0.08438\n",
      "Time:                        23:49:04   Log-Likelihood:                -337.22\n",
      "converged:                       True   LL-Null:                       -368.29\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.023e-12\n",
      "=====================================================================================\n",
      "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Elected Official?     0.9345      0.291      3.209      0.001       0.364       1.505\n",
      "const                 0.5137      0.248      2.074      0.038       0.028       0.999\n",
      "Obama Alum?           0.9038      0.429      2.105      0.035       0.062       1.745\n",
      "total_runners        -0.3775      0.058     -6.507      0.000      -0.491      -0.264\n",
      "STEM?                -0.4716      0.267     -1.769      0.077      -0.994       0.051\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "predictors = [ 'Partisan Lean', 'Race', 'Veteran?', 'LGBTQ?', 'Self-Funder?', 'STEM?','Obama Alum?', 'Elected Official?','total_runners']\n",
    "all_predictors_df = house[predictors]\n",
    "y = house['General Status']\n",
    "\n",
    "X = sm.add_constant(all_predictors_df)  #.drop returns a df\n",
    "X_shuffled = X.sample(frac=1, axis=1, random_state=42)\n",
    "\n",
    "\n",
    "# Fit the initial model with all features\n",
    "initial_model = sm.Logit(y, X_shuffled)\n",
    "initial_result = initial_model.fit()\n",
    "best_aic = initial_result.aic\n",
    "best_bic = initial_result.bic\n",
    "best_model = initial_model\n",
    "selected_features = list(X_shuffled.columns)\n",
    "\n",
    "# Backward selection\n",
    "\n",
    "# @ Nikki why do we drop the constant\n",
    "for feature in X_shuffled.columns[0:]:  # Exclude the constant term\n",
    "    # Fit the model without the current feature\n",
    "    X_subset = X_shuffled[selected_features].drop(feature, axis=1)\n",
    "    model = sm.Logit(y, X_subset)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Compare AIC and BIC\n",
    "    if result.aic < best_aic and result.bic < best_bic:\n",
    "        best_aic = result.aic\n",
    "        best_bic = result.bic\n",
    "        best_model = model\n",
    "        selected_features.remove(feature)\n",
    "\n",
    "# Fit the final model with the selected features\n",
    "final_result = best_model.fit()\n",
    "\n",
    "# Print the summary of the final model\n",
    "print(final_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ea1a7-23d5-4c72-b3d9-e10de1454962",
   "metadata": {},
   "source": [
    "Testing the best recommended features in a logistic regression model with sklearn: \n",
    "We will only take the four most signifcant regressors according to the forward and backwrard seelction modles/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "18f9468b-c6a7-4482-a8bd-d245187346db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "#house_important_only = house[house['Elected Official','STEM?','Obama Alum?', 'total_runners', 'General Status']]\n",
    "train, test = train_test_split(house, test_size = .30, random_state = 101)\n",
    "new_predictors = ['Elected Official?','STEM?','Obama Alum?', 'total_runners']\n",
    "X_train1, y_train1 = train[new_predictors], train['General Status']\n",
    "X_test1, y_test1 = test[new_predictors], test['General Status']\n",
    "\n",
    "logisticmodel1 = LogisticRegression(\n",
    "    penalty='none', solver='lbfgs'\n",
    ")\n",
    "\n",
    "logisticmodel1.fit(X_test1, y_test1)\n",
    "\n",
    "probs = logisticmodel1.predict_proba(X_test1)[:, 1]\n",
    "y_hat = (probs > 0.5).astype(np.int64)\n",
    "\n",
    "accuracy = np.mean(y_test == y_hat)\n",
    "print(f\"Accuracy on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf613b5c-3afc-4f89-a600-2eb775254174",
   "metadata": {},
   "source": [
    "Nonparametric models: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "55dd6514-c79d-4f7e-b49b-7a8b7597ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Using the optimal features selected in the previous section: -- dominic said to do all possible ones. \n",
    "\n",
    "X_cols = [ 'Partisan Lean', 'Race', 'Veteran?', 'LGBTQ?', 'Self-Funder?', 'STEM?','Obama Alum?', 'Elected Official?','total_runners']\n",
    "y_col = 'General Status'\n",
    "forest_model = RandomForestClassifier()\n",
    "\n",
    "train, test = train_test_split(house, test_size = .25, random_state = 101)\n",
    "forest_model.fit(train[X_cols], train['General Status'])\n",
    "\n",
    "train[\"forest_pred\"] = forest_model.predict(train[X_cols])\n",
    "test[\"forest_pred\"] = forest_model.predict(test[X_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8542264d-27cb-4b51-8719-85a069429d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set error for random forest: 0.27939053622117876\n",
      "Test set error for random forest:     0.6193930890332394\n",
      "Accuracy: 0.6163522012578616\n"
     ]
    }
   ],
   "source": [
    "train_rmse = np.mean((train[\"forest_pred\"] - train[y_col]) ** 2) ** 0.5\n",
    "test_rmse = np.mean((test[\"forest_pred\"] - test[y_col]) ** 2) ** 0.5\n",
    "forest_accuracy = accuracy_score(test[y_col], test[\"forest_pred\"])\n",
    "\n",
    "print(\"Training set error for random forest:\", train_rmse)\n",
    "print(\"Test set error for random forest:    \", test_rmse)\n",
    "print(\"Accuracy:\", forest_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ba892-6bbb-4f39-bc52-dd4302d7470b",
   "metadata": {},
   "source": [
    "Nonparametric models: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6f7f8747-4726-44bf-a266-4dfb350c4056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tree_model = DecisionTreeClassifier()\n",
    "\n",
    "tree_model.fit(train[X_cols], train[y_col])\n",
    "\n",
    "train[\"tree_pred\"] = tree_model.predict(train[X_cols])\n",
    "test[\"tree_pred\"] = tree_model.predict(test[X_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ba12afb8-4740-48ed-ad4c-676ef83b11f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set error for decision tree: 0.27939053622117876\n",
      "Test set error for decision tree:     0.6344412685745153\n",
      "Accuracy: 0.5974842767295597\n"
     ]
    }
   ],
   "source": [
    "train_rmse = np.mean((train[\"tree_pred\"] - train[y_col]) ** 2) ** 0.5\n",
    "test_rmse = np.mean((test[\"tree_pred\"] - test[y_col]) ** 2) ** 0.5\n",
    "\n",
    "print(\"Training set error for decision tree:\", train_rmse)\n",
    "print(\"Test set error for decision tree:    \", test_rmse)\n",
    "\n",
    "\n",
    "tree_accuracy = accuracy_score(test[y_col], test[\"tree_pred\"])\n",
    "print(\"Accuracy:\", tree_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c386dfe0-e80b-4057-b88d-e2e4e9ccf440",
   "metadata": {},
   "source": [
    "```\n",
    "Evaluation Metrics:\n",
    "\n",
    "Besides RMSE and accuracy, consider other metrics like precision, recall, F1 score, especially for imbalanced datasets.\n",
    "\n",
    "Model Complexity:\n",
    "\n",
    "Random Forest's max_features=1 might be too restrictive.\n",
    "Try adjusting max_features and other hyperparameters like n_estimators and max_depth.\n",
    "Model Overfitting:\n",
    "\n",
    "Both models might be overfitting to the training data.\n",
    "Consider implementing cross-validation to better understand model performance.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56fa09b-c869-42ea-87c2-83759601e779",
   "metadata": {},
   "source": [
    "## Looking into Prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "69972750-b009-4eb1-83d4-1aa0ae8c4fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence of wins: 0.2685624012638231\n"
     ]
    }
   ],
   "source": [
    "#number of rows in house to beign with that actually won. \n",
    "prevalence = len(house[house['General Status']==1])/len(house)\n",
    "print(\"Prevalence of wins:\", prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37df85f-de2e-46c4-a6f4-84898e5ad6bb",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 2b) Frequentist Regression\n",
    "\n",
    "Let's start by considering the problem from a frequentist lens. To do this, we'll use the `statsmodels.api`, which allows us to create a model in just a few lines of code.\n",
    "\n",
    "After fitting our model, we can call the `.summary()` method, and get a breakdown of our model and some details on how well it fit our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb338cb5-9844-4b09-9acc-d51e05f02e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af799ef-629f-48a6-8dfd-2264658187b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#FROM LAB \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Fit Poisson GLM model where Temp_Anomaly is a covariate (exogenous variable): No need to modify\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m freq_model \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241m.\u001b[39mGLM(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum_Storms\u001b[39m\u001b[38;5;124m\"\u001b[39m], exog \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTemp_Anomaly\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \n\u001b[1;32m      4\u001b[0m                   family\u001b[38;5;241m=\u001b[39msm\u001b[38;5;241m.\u001b[39mfamilies\u001b[38;5;241m.\u001b[39mPoisson())\n\u001b[1;32m      5\u001b[0m freq_res \u001b[38;5;241m=\u001b[39m freq_model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(freq_res\u001b[38;5;241m.\u001b[39msummary())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sm' is not defined"
     ]
    }
   ],
   "source": [
    "#FROM LAB \n",
    "# Fit Poisson GLM model where Temp_Anomaly is a covariate (exogenous variable): No need to modify\n",
    "freq_model = sm.GLM(df[\"Num_Storms\"], exog = sm.add_constant(df[\"Temp_Anomaly\"]), \n",
    "                  family=sm.families.Poisson())\n",
    "freq_res = freq_model.fit()\n",
    "print(freq_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2723faf-105c-44c4-8b5f-1fa2c1947232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = sm.OLS(np.log(Y), sm.add_constant(X)).fit()\n",
    "print(model_two.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8517d-2e33-47da-9b72-5f229f53f2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
