{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "131eaa77-ab5b-46a8-8be5-4401810fa774",
   "metadata": {},
   "source": [
    "## December 10th GLM From beginning to end with descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7984a-0b2c-410c-901b-02a2de8b8ca5",
   "metadata": {},
   "source": [
    "# Import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "465d2f39-a473-40da-b44c-f18c83523c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm\n",
    "from fuzzywuzzy import fuzz\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, balanced_accuracy_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, balanced_accuracy_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d23cb-a295-4ec5-be60-55b32b42d624",
   "metadata": {},
   "source": [
    "# Functions I wrote to do this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c92b317-2906-4dd5-bf6a-24dff03b3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_cols(df, nan_threshold=20):\n",
    "    few_NaNs_cols = []\n",
    "    for col in df.columns:\n",
    "        if (df[col].nunique(dropna=False) == 2) or (df[col].nunique(dropna=True) == 2):\n",
    "            unique_vals = df[col].unique()\n",
    "            if (unique_vals[0] !=0 and unique_vals[1] !=0):\n",
    "                print(f\"col:{col}\\n0 means:{unique_vals[0]}\\n1 means: {unique_vals[1]}\\n\")\n",
    "                df[col] = df[col].replace({unique_vals[0]: int(0), unique_vals[1]: int(1)})\n",
    "            df[col].fillna(0, inplace=True) #now this will only make sense tho if we OHE first.    \n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_columns(df, col_lst):\n",
    "    for i in col_lst:\n",
    "        if i in df.columns:\n",
    "            df.drop(i, axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def lowercase_column(df, column_name):\n",
    "    if column_name in df.columns:\n",
    "        df[column_name] = df[column_name].astype(str).str.lower()\n",
    "    return df\n",
    "\n",
    "def count_candidates_by_district(df, district_column, new_column_name):\n",
    "    district_counts = df.groupby(district_column).size().reset_index(name=new_column_name)\n",
    "    df_merged = df.merge(district_counts, on=district_column)\n",
    "    df_merged = df_merged[df_merged[new_column_name]>1]\n",
    "    return df_merged\n",
    "\n",
    "def move_column_to_front(df, col_lst):\n",
    "    for column_name in col_lst:\n",
    "        if column_name in df.columns:\n",
    "            df = df[[column_name] + [col for col in df.columns if col != column_name]]\n",
    "    return df\n",
    "\n",
    "def get_info(df):\n",
    "    print(f\"COL VALUE TYPES \\n{df.dtypes} \\n\\ndf shape:{df.shape}\\n\\nall the columns:\\n{df.columns}\")\n",
    "    \n",
    "    \n",
    "def rename_column_if_exists(df, old_name, new_name):\n",
    "    if old_name in df.columns:\n",
    "        df.rename(columns={old_name: new_name}, inplace=True)\n",
    "    return df\n",
    "    \n",
    "def replace_values_fill_na(df, column_name, replace_dict):\n",
    "    if column_name in df.columns:\n",
    "        df[column_name] = df[column_name].replace(replace_dict).fillna(0)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def get_ohe_cols(df, unique_limit=16, exclude = ['total_runners_house','total_runners']):\n",
    "    #object_cols = df.select_dtypes(include=['object']).columns\n",
    "    res = [col for col in df.columns if ((df[col].nunique(dropna=False) <= unique_limit) and (df[col].nunique(dropna=False)>2) and (col != 'total_runners') and (col != 'General Status') and (col !='Total Endorsements'))]\n",
    "    return res\n",
    "\n",
    "\n",
    "def convert_type(df, col_lst):\n",
    "    for column_name in col_lst:\n",
    "        if column_name in df.columns and df[column_name].dtype != 'int64':\n",
    "            df[column_name] = df[column_name].astype(int)\n",
    "\n",
    "            \n",
    "def get_X_df(df, y_col):\n",
    "    return df.drop(y_col, axis=1)\n",
    "\n",
    "# def zero_dropper(df):\n",
    "#     for col in df.columns:\n",
    "#         if ((df[col]==0).mean() >= 0.90):\n",
    "#             df = df.drop(col, axis=1)\n",
    "#     return df\n",
    "\n",
    "def drop_VIF_col(X, threshold=2):\n",
    "    while True:\n",
    "        vif_info = pd.DataFrame()\n",
    "        vif_info['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "        vif_info['Column'] = X.columns\n",
    "        vif_info = vif_info.sort_values('VIF', ascending=False)\n",
    "        max_VIF = vif_info['VIF'].iloc[0]\n",
    "\n",
    "        if max_VIF > threshold:\n",
    "            to_drop = vif_info['Column'].iloc[0]\n",
    "            print(f\"Dropped: {to_drop} with VIF of {max_VIF}\")\n",
    "            X = X.drop(to_drop, axis=1)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return X  # Returning the modified DataFrame\n",
    "\n",
    "def change_to_int(df, column):\n",
    "    df[column] = df[column].astype(int)\n",
    "    \n",
    "    \n",
    "def convert_to_int_if_possible(df, col_lst):\n",
    "    for column_name in col_lst:\n",
    "        temp_col = pd.to_numeric(df[column_name], errors='coerce')\n",
    "        if temp_col.isna().sum() == 0:\n",
    "            if all(temp_col.dropna() == temp_col.dropna().astype(int)):\n",
    "                df[column_name] = temp_col.astype(int)\n",
    "    return df\n",
    "\n",
    "def aic(X, y):\n",
    "    best_features = []\n",
    "    best_aic = float('inf')\n",
    "\n",
    "    for feature in X.columns:\n",
    "        # Create a temporary DataFrame with the current set of best features plus the new feature\n",
    "        X_temp = sm.add_constant(X[best_features + [feature]])\n",
    "\n",
    "       \n",
    "        model = sm.Logit(y, X_temp)  # Fit the logistic regression model\n",
    "        result = model.fit()  # disp=0 suppresses the fit output\n",
    "\n",
    "        # Check AIC and update if it is lower\n",
    "        if result.aic < best_aic:\n",
    "            best_aic = result.aic\n",
    "            best_features.append(feature)\n",
    "\n",
    "    # Fit the final model with the best features\n",
    "    X_final = sm.add_constant(X[best_features])\n",
    "    final_model = sm.Logit(y, X_final)\n",
    "    final_result = final_model.fit()\n",
    "\n",
    "    # You might want to return the final model, its summary, or AIC\n",
    "    print(f\"{best_features}\")\n",
    "    return final_result.summary(), final_result.aic\n",
    "\n",
    "\n",
    "\n",
    "def zero_dropper(df):\n",
    "    for col in df.columns:\n",
    "        if ((df[col]==1).mean() >= 0.90):\n",
    "            df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de4bbbe-b445-4bf5-b924-1c022c4747aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEC_merged = pd.read_csv('dec10.csv')\n",
    "FEC_merged = convert_to_int_if_possible(FEC_merged,list(FEC_merged.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ca882-9cb3-4897-a8bb-d00806ce39cf",
   "metadata": {},
   "source": [
    "## I'm going to OHE the columns that have more than two unique values (including NaNs) for example Emily Endorsed Yes, Emily Endorsed No, and Emily Endorsed NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf3caa45-0566-4999-b6fb-a409892a880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols =  get_ohe_cols(FEC_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ddb1fc-a42b-41f0-bd4f-5a87beae2b6e",
   "metadata": {},
   "source": [
    "Now I want to OHE those columns and then drop one (to avoid multicollinearity). BEcasue one of our objectives is explainability and interpretabiliyt, I don't want to drop jsut any column ,I waot to drop the _NaN column or the \"No information column\" if it exists, and if not, drop the column with the most 1s. The function ``` ohe_and_avoid_multicollinearity``` does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e78f9fd-dfc9-429d-a869-2d6c2e69359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_and_avoid_multicollinearity(df, columns_to_ohe):\n",
    "    \n",
    "    OHE_df = pd.get_dummies(df, columns = columns_to_ohe, drop_first=True)\n",
    "    OHE_df = OHE_df[[col for col in OHE_df.columns if col not in columns_to_ohe]]\n",
    "    return OHE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fe3f4f6-c43d-44cb-b4ef-781ed96f6316",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE_result = ohe_and_avoid_multicollinearity(FEC_merged, ohe_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496350e-7e83-4ced-b209-282cf499cc65",
   "metadata": {},
   "source": [
    "Now, I;m going to binarize columsn with exactly two unique values, and assing the result to binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19e38982-9d9b-4939-a4fa-49b2052e9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized = binarize_cols(OHE_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ecb750-2f00-4ae9-8122-03456d93313d",
   "metadata": {},
   "source": [
    "Now, I'm going to drop any columns where a majority of the values are 1. \n",
    "This is called the variance threshold. \n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b4bbf39-d422-45b9-ab76-0846c3ec7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_variance_drop(df):\n",
    "    for col in df.columns:\n",
    "        if ((df[col]==1).mean() >= 0.80):\n",
    "            df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58be073a-7b40-464b-b4e2-3061c0c6fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = low_variance_drop(binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d3bfaa-73eb-471c-b11e-a51b7bac27a3",
   "metadata": {},
   "source": [
    "Now, we do VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7acccfe8-7f06-429d-983f-89d4f031e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_VIF_col(X, threshold=2):\n",
    "    while True:\n",
    "        vif_info = pd.DataFrame()\n",
    "        vif_info['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "        vif_info['Column'] = X.columns\n",
    "        vif_info = vif_info.sort_values('VIF', ascending=False)\n",
    "        max_VIF = vif_info['VIF'].iloc[0]\n",
    "\n",
    "        if max_VIF > threshold:\n",
    "            to_drop = vif_info['Column'].iloc[0]\n",
    "            print(f\"Dropped: {to_drop} with VIF of {max_VIF}\")\n",
    "            X = X.drop(to_drop, axis=1)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return X  # Returning the modified DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bcf117ba-1a4f-4a00-85b0-19b4dedb786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: Party Support?_1.0 with VIF of inf\n",
      "Dropped: Position.on.Legalization.Decriminalization.of.Marijuana.Policy_Candidate provides no information with VIF of 354.87366495032614\n",
      "Dropped: Position.on.Climate.Change_Candidate supports regulations and measures to combat climate change with VIF of 159.63060482195527\n",
      "Dropped: Position.on.Gun.Control_Candidate supports gun control measures with VIF of 113.71850824525154\n",
      "Dropped: Position.on.Campaign.Finance.Reform_Candidate provides no information with VIF of 77.07177348717686\n",
      "Dropped: Total Endorsements with VIF of 68.53640281590212\n",
      "Dropped: Position.on.Criminal.Justice.Reform_Candidate provides no information with VIF of 58.69578496907571\n",
      "Dropped: Marital.Status_Married with VIF of 39.9321113020403\n",
      "Dropped: Position.on.Federal.Taxes_Candidate supports raising taxes on the wealthy/corporations with VIF of 38.66106803497006\n",
      "Dropped: Position.on.Social.Security_Candidate provides no information with VIF of 26.5974932101666\n",
      "Dropped: Position.on.Business.Regulations_Candidate provides no information with VIF of 25.047676600807936\n",
      "Dropped: Position.on.Minimum.Wage_Candidate provides no information with VIF of 19.924721838191154\n",
      "Dropped: Position.on.Immigration_Candidate supports comprehensive immigration reform (including a path to citizenship for illegal immigrants) with VIF of 13.652385542439564\n",
      "Dropped: Position.on.Affordable.Care.Act..ObamaCare._Candidate provides complicated/complex/unclear position with VIF of 13.046090851054995\n",
      "Dropped: Position.on.Defense.Spending_Candidate provides no information with VIF of 12.285350951201133\n",
      "Dropped: total_runners with VIF of 7.845732437811411\n",
      "Dropped: Education_Other with VIF of 5.629576907809664\n",
      "Dropped: SinglePayer with VIF of 3.848640749760186\n",
      "Dropped: Previous.Electoral.Experience with VIF of 3.2654082010237087\n",
      "Dropped: Position.on.Abortion_Candidate provides no information with VIF of 2.962592310863188\n",
      "Dropped: Position.on.Same.Sex.Marriage with VIF of 2.9130487427908123\n",
      "Dropped: Position.on.Federal.K.12.Education.Policy_Candidate provides no information with VIF of 2.7860522225469566\n",
      "Dropped: Position.on.Minimum.Wage_Candidate supports raising the minimum wage with VIF of 2.685527462981634\n",
      "Dropped: Party.Category_Progressive Democrat with VIF of 2.5845148576498933\n",
      "Dropped: Position.on.Federal.Taxes_Candidate provides no information with VIF of 2.5094910099901035\n",
      "Dropped: Position.on.Immigration_Candidate provides no information with VIF of 2.472438213053488\n",
      "Dropped: Position.on.Climate.Change_Candidate provides no information with VIF of 2.3369464415193413\n",
      "Dropped: Position.on.Campaign.Finance.Reform_Candidate supports reforming campaign finance (\"overturning Citizens United,\" \"no more SuperPACs,\" etc.) with VIF of 2.2302686176297453\n",
      "Dropped: Position.on.Criminal.Justice.Reform_Candidate supports major criminal justice reform with VIF of 2.110638524264606\n",
      "Dropped: receipts with VIF of 2.091492727852607\n",
      "Dropped: Female with VIF of 2.0470687247974357\n",
      "Dropped: Marital.Status_No information with VIF of 2.0235730708622426\n"
     ]
    }
   ],
   "source": [
    "X = reduced_df.drop('General Status', axis=1)\n",
    "best_X = drop_VIF_col(X)\n",
    "best_X_lst = list(best_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5434905-40aa-48bc-b206-c2b844142c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Partisan Lean',\n",
       " 'Race',\n",
       " 'LGBTQ?',\n",
       " 'Elected Official?',\n",
       " 'Self-Funder?',\n",
       " 'STEM?',\n",
       " 'Listed.military.service.',\n",
       " 'Obama Alum?_Yes',\n",
       " 'Emily Endorsed?_1.0',\n",
       " 'Gun Sense Candidate?_1.0',\n",
       " 'Biden Endorsed?_1.0',\n",
       " 'Warren Endorsed?_1.0',\n",
       " 'Sanders Endorsed?_1.0',\n",
       " 'Our Revolution Endorsed?_1.0',\n",
       " 'Justice Dems Endorsed?_1.0',\n",
       " 'PCCC Endorsed?_1.0',\n",
       " 'Indivisible Endorsed?_1.0',\n",
       " 'WFP Endorsed?_1.0',\n",
       " 'VoteVets Endorsed?_1.0',\n",
       " 'No Labels Support?_Yes',\n",
       " \"Education_Bachelor's or some college\",\n",
       " 'Education_J.D.',\n",
       " \"Education_Master's Degree (includes MBA)\",\n",
       " 'Education_Other Graduate',\n",
       " 'Marital.Status_Engaged',\n",
       " 'Marital.Status_Other',\n",
       " 'Marital.Status_Single',\n",
       " 'Marital.Status_Widowed',\n",
       " 'Position.on.Affordable.Care.Act..ObamaCare._Candidate provides no information',\n",
       " 'Position.on.Federal.Taxes_Candidate provides complicated/complex/unclear position',\n",
       " 'Position.on.Business.Regulations_Candidate provides complicated/complex/unclear position',\n",
       " 'Position.on.Business.Regulations_Candidate supports placing smart regulations on business',\n",
       " 'Position.on.National.Debt.Deficit_Candidate provides complicated/complex/unclear position',\n",
       " 'Position.on.National.Debt.Deficit_Candidate supports increasing the national debt or the federal deficit',\n",
       " 'Position.on.Social.Security_Candidate provides complicated/complex/unclear position',\n",
       " 'Position.on.Social.Security_Candidate supports protecting the status quo Social Security system',\n",
       " 'Position.on.Gun.Control_Candidate provides complicated/complex/unclear position',\n",
       " 'Position.on.Gun.Control_Candidate provides no information',\n",
       " 'Position.on.Abortion_Candidate identifies with the pro-life position (i.e. anti-abortion)',\n",
       " 'Position.on.Abortion_Candidate provides complicated/complex/unclear position',\n",
       " 'Position.on.Federal.K.12.Education.Policy_Candidate supports federal proposals for major education reform (including common core)',\n",
       " 'Position.on.Federal.K.12.Education.Policy_Candidate supports local solutions to reform education (e.g. opposes common core, etc.)',\n",
       " 'Position.on.Climate.Change_Candidate provides complicated/complex/unclear position',\n",
       " 'Position.on.Legalization.Decriminalization.of.Marijuana.Policy_Candidate provides complicated/complex/unclear position',\n",
       " 'Position.on.Legalization.Decriminalization.of.Marijuana.Policy_Candidate supports legalization/decriminalization of marijuana',\n",
       " 'Position.on.Defense.Spending_Candidate provides complicated/complex/unclear position',\n",
       " 'Position.on.Defense.Spending_Candidate supports a reduction in military spending',\n",
       " 'Position.on.Handling.Terrorism.Abroad_Candidate supports calls for increased American intervention to combat terrorism',\n",
       " 'Position.on.Handling.Terrorism.Abroad_Candidate supports status quo efforts to combat terrorism',\n",
       " 'Position.on.Russia_Candidate notes Russia as political enemy of the United States',\n",
       " 'Position.on.Russia_Candidate provides complicated/complex/unclear position',\n",
       " 'Party.Category_Moderate Democrat',\n",
       " 'Party.Category_Other']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_X_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e932b6e-af60-49da-909f-9875eae0b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_sel_df = reduced_df[['General Status']+best_X_lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc02881-de81-4a4f-9717-2cad29f04d0c",
   "metadata": {},
   "source": [
    "Now we want to call the aic function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f766c47-bc88-41be-95dc-29293c6aeb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.602383\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.601459\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.602383\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.595734\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.595273\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592111\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591846\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.587725\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.554955\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532697\n",
      "         Iterations 6\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfwd_sel_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_X_lst\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfwd_sel_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGeneral Status\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 111\u001b[0m, in \u001b[0;36maic\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    107\u001b[0m X_temp \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X[best_features \u001b[38;5;241m+\u001b[39m [feature]])\n\u001b[1;32m    110\u001b[0m model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mLogit(y, X_temp)  \u001b[38;5;66;03m# Fit the logistic regression model\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# disp=0 suppresses the fit output\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Check AIC and update if it is lower\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39maic \u001b[38;5;241m<\u001b[39m best_aic:\n",
      "File \u001b[0;32m/srv/conda/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py:1983\u001b[0m, in \u001b[0;36mLogit.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1980\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(DiscreteModel\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m,\n\u001b[1;32m   1982\u001b[0m         full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1983\u001b[0m     bnryfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1984\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1985\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1986\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1989\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1991\u001b[0m     discretefit \u001b[38;5;241m=\u001b[39m LogitResults(\u001b[38;5;28mself\u001b[39m, bnryfit)\n\u001b[1;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[0;32m/srv/conda/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py:230\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "File \u001b[0;32m/srv/conda/lib/python3.9/site-packages/statsmodels/base/model.py:579\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m cov_params_func(\u001b[38;5;28mself\u001b[39m, xopt, retvals)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m full_output:\n\u001b[0;32m--> 579\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mretvals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHessian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hessian:\n\u001b[1;32m    581\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhessian(xopt)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/lib/python3.9/site-packages/numpy/linalg/linalg.py:538\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    536\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    537\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 538\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/srv/conda/lib/python3.9/site-packages/numpy/linalg/linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "aic(fwd_sel_df[best_X_lst].astype(float),fwd_sel_df['General Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a04ef-7bfa-4f5f-81aa-f0680d8aedcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
